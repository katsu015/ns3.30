{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.gray();\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "import skimage\n",
    "from skimage import color, data, filters, restoration, morphology, measure, segmentation\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray, rgb2hsv\n",
    "from skimage.transform import rotate, resize\n",
    "from skimage.transform import AffineTransform, ProjectiveTransform, warp \n",
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "from skimage.filters import gaussian, gabor_kernel, gabor\n",
    "from skimage.feature import canny, match_template\n",
    "from skimage.feature import corner_harris, corner_fast, blob_dog, ORB\n",
    "from skimage.feature import match_descriptors, corner_peaks, plot_matches, corner_subpix\n",
    "from sklearn.cluster import KMeans, MeanShift\n",
    "from skimage.measure import ransac\n",
    "from skimage.segmentation import active_contour\n",
    "\n",
    "\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n",
    "from scipy import fft\n",
    "\n",
    "\n",
    "from time import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, RadioButtons\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_func(r, c, sigma = 1):\n",
    "    return np.exp(-np.hypot(r, c)/sigma) / 2 / np.pi / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ウィーナフィルタによる画像の復元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = rgb2gray(imread('girl.jpg'))\n",
    "\n",
    "\n",
    "@interact(noise=(0, 1, 0.1), \n",
    "          balance=(1, 50, 1),\n",
    "          sigma=(1, 20, 1))\n",
    "def g(noise=0.3, sigma=10, balance=10):\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 3))\n",
    "\n",
    "    fig.add_subplot(1, 4, 1)\n",
    "    imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.title('original image')\n",
    "\n",
    "\n",
    "    fig.add_subplot(1, 4, 2)\n",
    "    impulse = np.zeros((sigma*5, sigma*5)) # use five sigma\n",
    "    h, w = impulse.shape\n",
    "    impulse[h//2, w//2] = 1\n",
    "    psf = gaussian(impulse, sigma=sigma)\n",
    "    imshow(psf)\n",
    "    plt.title('PSF: sigma={}'.format(sigma))\n",
    "\n",
    "    \n",
    "    fig.add_subplot(1, 4, 3)\n",
    "    img = signal.fftconvolve(im, psf, mode='same')\n",
    "    img += noise * img.std() * np.random.standard_normal(img.shape) # 画像をPFSでぼかしてノイズを加える\n",
    "    imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('observed image')\n",
    "    \n",
    "\n",
    "    fig.add_subplot(1, 4, 4)\n",
    "    deconvolved_img = restoration.wiener(img, psf, balance)\n",
    "    imshow(deconvolved_img, vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.title('restored image, balance {}'.format(balance))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDR合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axel Jacobs (Photographer) - Axel Jacobs, WebHDR CC BY-SA 2.0\n",
    "# https://commons.wikimedia.org/wiki/File:HDRI_Sample_Scene_Window_-_01.jpg\n",
    "# ..\n",
    "# https://commons.wikimedia.org/wiki/File:HDRI_Sample_Scene_Window_-_12.jpg\n",
    "\n",
    "urls = \\\n",
    "['https://upload.wikimedia.org/wikipedia/commons/5/51/HDRI_Sample_Scene_Window_-_01.jpg',\n",
    "'https://upload.wikimedia.org/wikipedia/commons/c/c1/HDRI_Sample_Scene_Window_-_02.jpg',\n",
    "'https://upload.wikimedia.org/wikipedia/commons/5/5b/HDRI_Sample_Scene_Window_-_03.jpg',\n",
    "'https://upload.wikimedia.org/wikipedia/commons/6/6e/HDRI_Sample_Scene_Window_-_04.jpg',\n",
    "'https://upload.wikimedia.org/wikipedia/commons/d/d1/HDRI_Sample_Scene_Window_-_05.jpg',\n",
    "'https://upload.wikimedia.org/wikipedia/commons/5/51/HDRI_Sample_Scene_Window_-_06.jpg',\n",
    "'https://upload.wikimedia.org/wikipedia/commons/b/b6/HDRI_Sample_Scene_Window_-_07.jpg',\n",
    "'https://upload.wikimedia.org/wikipedia/commons/f/f8/HDRI_Sample_Scene_Window_-_08.jpg',\n",
    "'https://upload.wikimedia.org/wikipedia/commons/8/83/HDRI_Sample_Scene_Window_-_09.jpg',\n",
    "'https://upload.wikimedia.org/wikipedia/commons/c/c0/HDRI_Sample_Scene_Window_-_10.jpg',\n",
    "'https://upload.wikimedia.org/wikipedia/commons/6/6e/HDRI_Sample_Scene_Window_-_11.jpg',\n",
    "'https://upload.wikimedia.org/wikipedia/commons/8/8b/HDRI_Sample_Scene_Window_-_12.jpg']\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for i, url in enumerate(urls):\n",
    "    filename = 'hdr_{:02d}.jpg'.format(i)\n",
    "    print(url, filename)\n",
    "#     download(url, filename)\n",
    "    filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exposure_time(fn):\n",
    "    # EXIFから露光時間を取り出す\n",
    "    im = Image.open(fn)\n",
    "    exif = im._getexif()\n",
    "    exposure_time = exif[33434]\n",
    "    exposure_time = exposure_time[0] / exposure_time[1]\n",
    "    return exposure_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各画像の露光時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 2))\n",
    "\n",
    "for i, fn in enumerate(filenames):\n",
    "\n",
    "    fig.add_subplot(1, 12, i+1)\n",
    "    im = imread(fn)\n",
    "    imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.title('{:.03f}'.format(get_exposure_time(fn))) # 露光時間（秒）\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_list = []\n",
    "for fn in filenames:\n",
    "    im = cv2.imread(fn)\n",
    "    im = cv2.resize(im, (320, 240))\n",
    "    im_list.append(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDR画像の合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_mertens = cv2.createMergeMertens()\n",
    "hdr = merge_mertens.process(im_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トーンマッピングによるLDR表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@interact(gamma=(0.1, 3, 0.1), saturation=(0.1, 5, 0.1))\n",
    "def g(gamma=1, saturation=1):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    tonemap1 = cv2.createTonemap(gamma=gamma)\n",
    "    ldr1 = tonemap1.process(hdr.copy())\n",
    "    ldr1 = cv2.cvtColor(ldr1, cv2.COLOR_BGR2RGB)\n",
    "    imshow(ldr1)\n",
    "    plt.axis('off')\n",
    "    plt.title('Tone mappging method 1')\n",
    "\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    tonemap2 = cv2.createTonemapDrago(gamma=gamma, saturation=saturation)\n",
    "    ldr2 = tonemap2.process(hdr.copy())\n",
    "    ldr2 = cv2.cvtColor(ldr2, cv2.COLOR_BGR2RGB)\n",
    "    imshow(ldr2)\n",
    "    plt.axis('off')\n",
    "    plt.title('Tone mappging method 2')\n",
    "\n",
    "\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 領域分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Felsenszwalb: RGB画像を格子グラフとみなして最小全域木（minimum spanning tree）で分割する手法\n",
    "https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.felzenszwalb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('girl.jpg')\n",
    "\n",
    "@interact(scale=(10, 150, 10))\n",
    "def g(scale=50):\n",
    "\n",
    "    st = time()\n",
    "    img_seg = segmentation.felzenszwalb(img, scale=scale, sigma=3.0, min_size=20)\n",
    "    et = time() - st\n",
    "\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "    fig.add_subplot(1, 2, 1)   \n",
    "    imshow(segmentation.mark_boundaries(img, img_seg, color=(1, 1, 1))) # 領域分割結果を境界線で表示\n",
    "    plt.axis('off')\n",
    "    plt.title('segmentation result ({:.2f} sec)'.format(et))\n",
    "\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    imshow(color.label2rgb(img_seg)) # ラベリング結果をカラーで表示．\n",
    "    plt.axis('off')\n",
    "    plt.title('segmentation label')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- slic (simple linear iterative clustering): XYZ色空間と座標をk-meansでクラスタリングしてsuperpixelを作成する手法\n",
    "https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('girl.jpg')\n",
    "\n",
    "@interact(n_segments=(10, 300, 10),\n",
    "          compactness=(1, 30, 1))\n",
    "def g(n_segments=100, compactness=10):\n",
    "    \n",
    "    st = time()\n",
    "    img_seg = segmentation.slic(img, n_segments=n_segments, compactness=compactness)\n",
    "    et = time() - st\n",
    "\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "    fig.add_subplot(1, 2, 1)   \n",
    "    imshow(segmentation.mark_boundaries(img, img_seg, color=(1, 1, 1))) # 領域分割結果を境界線で表示\n",
    "    plt.axis('off')\n",
    "    plt.title('segmentation result ({:.2f} sec)'.format(et))\n",
    "\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    imshow(color.label2rgb(img_seg)) # ラベリング結果をカラーで表示．\n",
    "    plt.axis('off')\n",
    "    plt.title('segmentation label')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- quickshift：XYZ色空間と座標をquickshiftでクラスタリングする手法\n",
    "https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.quickshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('girl.jpg')\n",
    "\n",
    "@interact(ratio=(0, 1, 0.1),\n",
    "          kernel_size=(1, 30, 1),\n",
    "          max_dist=(1, 30, 1))\n",
    "def g(ratio=100, kernel_size=5, max_dist=10):\n",
    "    \n",
    "    st = time()\n",
    "    img_seg = segmentation.quickshift(img, ratio=ratio, kernel_size=kernel_size, max_dist=max_dist)\n",
    "    et = time() - st\n",
    "\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    imshow(segmentation.mark_boundaries(img, img_seg, color=(1, 1, 1))) # 領域分割結果を境界線で表示\n",
    "    plt.axis('off')\n",
    "    plt.title('segmentation result ({:.2f} sec)'.format(et))\n",
    "\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    imshow(color.label2rgb(img_seg)) # ラベリング結果をカラーで表示．\n",
    "    plt.axis('off')\n",
    "    plt.title('segmentation label, ratio {0:.1f}, ksize {1}, max_dist {2}'.format(ratio, kernel_size, max_dist))\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- watershed：画像の凹凸を山谷とみなして水の溜まる場所を見つけるwatershedを利用する手法\n",
    "https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('girl.jpg')\n",
    "\n",
    "@interact(markers=(0, 25000, 100),\n",
    "          compactness=(0, 0.5, 0.1))\n",
    "def g(markers=5000, compactness=0.1):\n",
    "    \n",
    "    st = time()\n",
    "    markers = markers if markers > 0 else None\n",
    "    img_seg = segmentation.watershed(img, markers=markers, compactness=compactness)[:, :, 0] # なぜか3チャンネルで返される\n",
    "    et = time() - st\n",
    "\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    imshow(segmentation.mark_boundaries(img, img_seg, color=(1, 1, 1))) # 領域分割結果を境界線で表示\n",
    "    plt.axis('off')\n",
    "    plt.title('segmentation result ({:.2f} sec)'.format(et))\n",
    "\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    imshow(color.label2rgb(img_seg)) # ラベリング結果をカラーで表示．\n",
    "    plt.axis('off')\n",
    "    plt.title('segmentation label')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-meansクラスタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = imread('girl.jpg')\n",
    "im = resize(im, (im.shape[0]//3, im.shape[1]//3))\n",
    "\n",
    "clustering = KMeans(n_clusters=10)\n",
    "\n",
    "X = im.reshape((-1, 3))\n",
    "# clustering.fit(X[::1000, :]) # 画素数を1/1000に間引き\n",
    "clustering.fit(X)\n",
    "\n",
    "\n",
    "result = clustering.predict(X)\n",
    "img_seg = result.reshape(im.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)   \n",
    "imshow(segmentation.mark_boundaries(im, img_seg, color=(1, 1, 1))) # 領域分割結果を境界線で表示\n",
    "plt.axis('off')\n",
    "plt.title('segmentation result')\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "imshow(color.label2rgb(img_seg)) # ラベリング結果をカラーで表示．\n",
    "plt.axis('off')\n",
    "plt.title('segmentation label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ガボール特徴も利用したkmeansクラスタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rgb2gray(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,9))\n",
    "\n",
    "n_i = 3\n",
    "n_j = 10\n",
    "\n",
    "for j in tqdm(range(n_i)):\n",
    "    for i in tqdm(range(n_j), leave=False):\n",
    "        ax = fig.add_subplot(n_i, n_j, i+1 + j*n_j)\n",
    "        gabor_filter = gabor_kernel(frequency=0.1 * (j+1), bandwidth=1/(2*j+1), theta=0.4 * i).real\n",
    "        imshow(gabor_filter)\n",
    "        plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,9))\n",
    "\n",
    "gabor_features = []\n",
    "\n",
    "n_i = 3\n",
    "n_j = 10\n",
    "\n",
    "for j in tqdm(range(n_i)):\n",
    "    for i in tqdm(range(n_j), leave=False):\n",
    "        ax = fig.add_subplot(n_i, n_j, i+1 + j*n_j)\n",
    "        im_gabor = gabor(img, frequency=0.1 * (j+1), bandwidth=1/(2*j+1), theta=0.4 * i)\n",
    "        gabor_features.append(im_gabor[0]) # tuble (real, imag)\n",
    "        imshow(im_gabor[0], cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabor_texture = np.array(gabor_features).transpose(1,2,0).reshape((-1, n_i*n_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((im.reshape((-1, 3)), gabor_texture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean(axis=0), X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X -= X.mean(axis=0)\n",
    "X /= X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean(axis=0), X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = KMeans(n_clusters=10)\n",
    "\n",
    "# clustering.fit(X[::1000, :]) # 画素数を1/1000に間引き\n",
    "clustering.fit(X)\n",
    "\n",
    "\n",
    "result = clustering.predict(X)\n",
    "img_seg = result.reshape(img.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)   \n",
    "imshow(segmentation.mark_boundaries(im, img_seg, color=(1, 1, 1))) # 領域分割結果を境界線で表示\n",
    "plt.axis('off')\n",
    "plt.title('segmentation result')\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "imshow(color.label2rgb(img_seg)) # ラベリング結果をカラーで表示．\n",
    "plt.axis('off')\n",
    "plt.title('segmentation label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 動的輪郭モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rgb2gray(imread('coins.jpg'))\n",
    "imshow(img)\n",
    "img_s = gaussian(img, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### image boundary\n",
    "# h, w = img.shape[:3]\n",
    "# margin = 5\n",
    "# N = 50\n",
    "# y = \\\n",
    "# np.concatenate((np.array([margin]*N),\n",
    "#                 np.linspace(margin, h-1-margin, N),\n",
    "#                 np.array([h-1-margin]*N),\n",
    "#                 np.linspace(margin, h-1-margin, N)))\n",
    "# x = \\\n",
    "# np.concatenate((np.linspace(margin, w-1-margin, N),\n",
    "#                 np.array([w-1-margin]*N),\n",
    "#                 np.linspace(w-1-margin, margin, N),\n",
    "#                 np.array([margin]*N),\n",
    "#                ))\n",
    "\n",
    "#### circle\n",
    "s = np.linspace(0, 2*np.pi, 100)\n",
    "y = 100 + 80 * np.sin(s)\n",
    "x = 100 + 80 * np.cos(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snake = np.stack((y, x), axis=1)\n",
    "\n",
    "all_snake = [snake]\n",
    "for i in range(100):\n",
    "    snake = active_contour(img_s,\n",
    "                           snake,\n",
    "#                            alpha=0.01, beta=5,\n",
    "                           alpha=0.02, beta=5,\n",
    "#                            alpha=0.05, beta=5,\n",
    "#                            alpha=0.1, beta=5,\n",
    "                           max_iterations=10,\n",
    "                           coordinates='rc')\n",
    "    all_snake.append(snake)\n",
    "\n",
    "@interact(itr=(0, len(all_snake)-1, 1))\n",
    "def g(itr=0):\n",
    "    imshow(img)\n",
    "    plt.plot(all_snake[0][:, 1], all_snake[0][:, 0], '.w', lw=5)\n",
    "    plt.plot(all_snake[itr][:, 1], all_snake[itr][:, 0], '.r', lw=5)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テンプレートマッチング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = imread('flag.png')[:, :, :3] # remove alpha channel\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "\n",
    "fig.add_subplot(1, 2, 1)\n",
    "imshow(im)\n",
    "plt.title(\"original image\")\n",
    "\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "template = im[650:720, 843:960]\n",
    "imshow(template, interpolation='none')\n",
    "plt.title('template')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(angle=(-180, 180, 1))\n",
    "def g(angle=0):\n",
    "    \n",
    "    im_rot = rotate(im, angle=angle, resize=False)\n",
    "\n",
    "    ncc = match_template(rgb2gray(im_rot), rgb2gray(template))\n",
    "    x, y = np.unravel_index(np.argmax(ncc), ncc.shape)[::-1] # y,x --> x,y\n",
    "\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "    imshow(im // 2)\n",
    "\n",
    "    th, tw, _ = template.shape\n",
    "    ax.add_patch(plt.Rectangle((x, y), tw, th, edgecolor='r', facecolor='none', lw=3))\n",
    "    plt.title('detected template as rectangle')\n",
    "\n",
    "\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    imshow(ncc)\n",
    "    plt.title('NCC')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ハフ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = rgb2gray(imread('card.jpg'))\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)\n",
    "imshow(im)\n",
    "plt.axis('off')\n",
    "plt.title('original image')\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "im_edge = canny(im, sigma=3, low_threshold=40/255, high_threshold=100/255)\n",
    "imshow(im_edge)\n",
    "plt.axis('off')\n",
    "plt.title('Canny edge')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = np.linspace(-np.pi / 2, np.pi / 2, 360)\n",
    "voting_space, theta, rho = hough_line(im_edge, theta=angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.log(1 + voting_space),\n",
    "       extent=[np.rad2deg(theta[-1]), np.rad2deg(theta[0]), rho[-1], rho[0]],\n",
    "       cmap='gray_r', aspect=0.08)\n",
    "plt.xlabel('$\\\\theta$')\n",
    "plt.ylabel('$\\\\rho$')\n",
    "plt.title('voting space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, line_theta, line_rho = hough_line_peaks(voting_space, theta, rho, \n",
    "                                           threshold=0.3*voting_space.max(), num_peaks=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0\n",
    "x1 = im.shape[1]\n",
    "for angle, r in zip(line_theta, line_rho):\n",
    "    y0 = (r - x0 * np.cos(angle)) / np.sin(angle)\n",
    "    y1 = (r - x1 * np.cos(angle)) / np.sin(angle)\n",
    "    plt.plot((x0, x1), (y0, y1), '-r')\n",
    "imshow(im)\n",
    "plt.title('lines found by hough transform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴点検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = imread('Colosseum.jpg')\n",
    "img = rgb2gray(im)\n",
    "imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(max_sigma=(10, 300, 10), \n",
    "          threshold=(0.02, 1, 0.02))\n",
    "def g(max_sigma=50, threshold=0.2):\n",
    "        \n",
    "    keypoints1 = blob_dog(img, max_sigma=max_sigma, threshold=threshold, overlap=1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "    imshow(im)\n",
    "\n",
    "    for k in keypoints1:\n",
    "        y, x, s = k\n",
    "        ax.add_patch(plt.Circle((x, y), s, edgecolor='r', facecolor='none', lw=1))\n",
    "\n",
    "    plt.title('# keypoints {0}'.format(len(keypoints1)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(n=(1, 16, 1), \n",
    "          threshold=(0.05, 0.5, 0.01))\n",
    "def g(n=12, threshold=0.15):\n",
    "\n",
    "    keypoints1 = corner_peaks(corner_fast(img, n=n, threshold=threshold))\n",
    "\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "    imshow(im)\n",
    "\n",
    "    ax.scatter(keypoints1[:, 1], keypoints1[:, 0], color='r', marker='o', s=5)\n",
    "\n",
    "    plt.title('# keypoints {0}'.format(len(keypoints1)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(k=(0, 0.3, 0.01),\n",
    "          sigma=(0.5, 3, 0.5))\n",
    "def g(k=0.05, sigma=1):\n",
    "\n",
    "    keypoints1 = corner_peaks(corner_harris(img, k=k, sigma=sigma))\n",
    "\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "    imshow(im)\n",
    "\n",
    "    ax.scatter(keypoints1[:, 1], keypoints1[:, 0], color='r', marker='o', s=5)\n",
    "\n",
    "    plt.title('# keypoints {0}'.format(len(keypoints1)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(maxCorners=(10,500,10),\n",
    "          blockSize=(1,20,1))\n",
    "def g(maxCorners=60, blockSize=3):\n",
    "\n",
    "    keypoints1 = cv2.goodFeaturesToTrack(img.astype(np.float32),\n",
    "                                         maxCorners=maxCorners,\n",
    "                                         qualityLevel=0.01,\n",
    "                                         minDistance=5,\n",
    "                                         blockSize=blockSize)\n",
    "    keypoints1 = np.squeeze(keypoints1)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "    imshow(im)\n",
    "\n",
    "    ax.scatter(keypoints1[:, 0], keypoints1[:, 1], color='r', marker='o', s=5)\n",
    "\n",
    "\n",
    "    plt.title('# keypoints {0} {1}'.format(len(keypoints1), blockSize))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AKAZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(descriptor_type=[3,5],\n",
    "          threshold=(0.0001, 0.005, 0.0001))\n",
    "def g(threshold=0.001, descriptor_type=3):\n",
    "\n",
    "    detector = cv2.AKAZE_create(descriptor_type=descriptor_type, threshold=threshold)\n",
    "    keypoints1, descriptors1 = detector.detectAndCompute(im, None)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "    imshow(im)\n",
    "\n",
    "    for k in keypoints1:\n",
    "        x, y = k.pt\n",
    "        s = k.size\n",
    "        ax.add_patch(plt.Circle((x, y), s, edgecolor='r', facecolor='none', lw=1))\n",
    "\n",
    "\n",
    "    plt.title('# keypoints {0}'.format(len(keypoints1)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(thresh=(10, 200, 10))\n",
    "def g(thresh=100):\n",
    "\n",
    "    detector = cv2.BRISK_create(thresh=thresh)\n",
    "    keypoints1, descriptors1 = detector.detectAndCompute(im, None)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "    imshow(im)\n",
    "\n",
    "    for k in keypoints1:\n",
    "        x, y = k.pt\n",
    "        s = k.size\n",
    "        ax.add_patch(plt.Circle((x, y), s, edgecolor='r', facecolor='none', lw=1))\n",
    "\n",
    "\n",
    "    plt.title('# keypoints {0}'.format(len(keypoints1)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(n_keypoints=(100, 2000, 100))\n",
    "def g(n_keypoints=1000):\n",
    "\n",
    "    descriptor_extractor = ORB(n_keypoints=n_keypoints)\n",
    "    descriptor_extractor.detect_and_extract(img)\n",
    "    keypoints1 = descriptor_extractor.keypoints # 特徴点の(y,x)座標\n",
    "    # descriptors1 = descriptor_extractor.descriptors # 特徴量ベクトル\n",
    "\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "    imshow(im)\n",
    "\n",
    "    ax.scatter(keypoints1[:, 1], keypoints1[:, 0], color='r', marker='o', s=5)\n",
    "\n",
    "    plt.title('# keypoints {0}'.format(len(keypoints1)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パノラマ画像作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = imread('Colosseum.jpg')\n",
    "img2 = img1.copy()\n",
    "\n",
    "img1 = img1[:250, :300]\n",
    "img1 = rotate(img1, angle=45, resize=True)\n",
    "\n",
    "img2 = img2[100:, 200:600]\n",
    "img2 = rotate(img2, angle=-5, resize=True)\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)\n",
    "imshow(img1)\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "imshow(img2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 実画像を重ね合わせてみるための画像の例はこちら．\n",
    "\n",
    "# # Peter Haas CC BY-SA 3.0\n",
    "# # https://commons.wikimedia.org/wiki/File:Notre-Dame_de_Paris_2013-07-24.jpg\n",
    "# img1 = imread('https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Notre-Dame_de_Paris_2013-07-24.jpg/355px-Notre-Dame_de_Paris_2013-07-24.jpg')/255\n",
    "\n",
    "# # Dietmar Rabich CC BY-SA 4.0\n",
    "# # https://commons.wikimedia.org/wiki/File:Paris,_Notre_Dame_--_2014_--_1445.jpg\n",
    "# img2 = imread('https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Paris%2C_Notre_Dame_--_2014_--_1445.jpg/301px-Paris%2C_Notre_Dame_--_2014_--_1445.jpg')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像周囲を黒画素で拡張しておきます（後の処理を簡単にするため）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(im, pad=200):\n",
    "    h, w = im.shape[:2]\n",
    "    im_pad = np.zeros((h+2*pad, w+2*pad, 3))\n",
    "    im_pad[pad:pad+h, pad:pad+w] = im\n",
    "    return im_pad\n",
    "    \n",
    "img1 = padding(img1)\n",
    "img2 = padding(img2)\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)\n",
    "imshow(img1)\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "imshow(img2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カラー画像はグレースケールに変換\n",
    "img1g = rgb2gray(img1)\n",
    "img2g = rgb2gray(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-imageのORB特徴量を使います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORB特徴量を使います\n",
    "descriptor_extractor = ORB(n_keypoints=1000)\n",
    "\n",
    "# 画像1から特徴を検出\n",
    "descriptor_extractor.detect_and_extract(img1g)\n",
    "keypoints1 = descriptor_extractor.keypoints # 特徴点の(y,x)座標\n",
    "descriptors1 = descriptor_extractor.descriptors # 特徴量ベクトル\n",
    "\n",
    "# 画像2から特徴を検出\n",
    "descriptor_extractor.detect_and_extract(img2g)\n",
    "keypoints2 = descriptor_extractor.keypoints # 特徴点の(y,x)座標\n",
    "descriptors2 = descriptor_extractor.descriptors # 特徴量ベクトル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "別の特徴量を使うときには以下のコードをコメントアウトして使ってください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BRISK特徴量を使います\n",
    "# detector = cv2.BRISK_create()\n",
    "\n",
    "# # AKAZE特徴量を使います\n",
    "# detector = cv2.AKAZE_create()\n",
    "\n",
    "# # 画像1から特徴を検出\n",
    "# keypoints1, descriptors1 = detector.detectAndCompute((img1*255).astype(np.uint8), None)\n",
    "# keypoints1 = np.array([(k.pt[1], k.pt[0]) for k in keypoints1]) # (x,y) --> (y,x)\n",
    "\n",
    "# # 画像2から特徴を検出\n",
    "# keypoints2, descriptors2 = detector.detectAndCompute((img2*255).astype(np.uint8), None)\n",
    "# keypoints2 = np.array([(k.pt[1], k.pt[0]) for k in keypoints2]) # (x,y) --> (y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量のマッチングをします\n",
    "matches12 = match_descriptors(descriptors1, descriptors2, cross_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マッチング結果を表示します．対応する点が線で結ばれています．間違っているのもありますね．\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = plt.axes()\n",
    "plot_matches(ax,\n",
    "             img1, img2, \n",
    "             keypoints1, keypoints2, \n",
    "             matches12)\n",
    "ax.axis('off')\n",
    "# ax.set_title('Correspondences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANSACという方法で，間違っている対応（誤対応）を除去します．\n",
    "\n",
    "http://scikit-image.org/docs/dev/auto_examples/plot_matching.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対応点をsrcとdstに入れます\n",
    "src = [] # img1\n",
    "dst = [] # img2\n",
    "for coord in matches12:\n",
    "    src.append( keypoints1[coord[0]] )\n",
    "    dst.append( keypoints2[coord[1]] )\n",
    "src = np.array(src)\n",
    "dst = np.array(dst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANSAC実行\n",
    "model_robust, inliers = ransac((src, dst), \n",
    "#                                AffineTransform, min_samples=3,\n",
    "                               ProjectiveTransform, min_samples=4,\n",
    "                               residual_threshold=2, \n",
    "                               max_trials=2000)\n",
    "inlier_idxs = np.nonzero(inliers)[0] # 正しい対応（インライア）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANSAC後の対応点を見てみよう．誤対応が少なくなっていますね"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "ax = plt.axes()\n",
    "plot_matches(ax, \n",
    "             img1, img2,\n",
    "             src, dst,\n",
    "             np.column_stack((inlier_idxs, inlier_idxs)) )\n",
    "ax.axis('off')\n",
    "# ax.set_title('Correct correspondences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それではあらためて，正しい対応（インライア）だけを使って変換パラメータを推定しなおします．\n",
    "\n",
    "#src = src[inliers] # インライアだけを取り出す\n",
    "#src = src[:, [1,0] ] # (y,x)座標ベクトルを(x,y)座標ベクトルに変換する\n",
    "#\n",
    "#dst = dst[inliers]\n",
    "#dst = dst[:, [1,0] ]\n",
    "#\n",
    "#model_robust.estimate( src, dst )\n",
    "\n",
    "\n",
    "#上と同じことを1行でやってます\n",
    "model_robust.estimate( src[inliers][:, [1,0] ], dst[inliers][:, [1,0] ] )\n",
    "\n",
    "\n",
    "#注釈：\n",
    "# keypoint, ransac, plot_matchは(y,x)座標ベクトルを使っていますが，\n",
    "# warpは(x,y)座標ベクトルを使います．だから，ここでxyを変化して推定しなおしています"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推定された変換パラメータはこれ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(model_robust) == AffineTransform:\n",
    "    print(\"scale: \", model_robust.scale)\n",
    "    print(\"translation [pixels]: \", model_robust.translation)\n",
    "    print(\"rotaiton [radians]: \", model_robust.rotation)\n",
    "print(\"Transform matrix:\")\n",
    "print(model_robust.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは画像2と1を合成しましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)\n",
    "img_warped1 = warp( img1, model_robust.inverse )\n",
    "imshow(img_warped1)\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "img_warped2 = img2\n",
    "imshow(img_warped2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2枚の画像のサイズが違うので同じサイズにします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pano = np.zeros((max(img_warped1.shape[0], img_warped2.shape[0]),\n",
    "                     max(img_warped1.shape[1], img_warped2.shape[1]), 3), dtype=np.float)\n",
    "\n",
    "img_pano1 = img_pano.copy()\n",
    "img_pano1[:img_warped1.shape[0], :img_warped1.shape[1]] = img_warped1\n",
    "\n",
    "img_pano2 = img_pano.copy()\n",
    "img_pano2[:img_warped2.shape[0], :img_warped2.shape[1]] = img_warped2\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)\n",
    "imshow(img_pano1)\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "imshow(img_pano2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "足してみよう．パノラマができたかな？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "img_pano = (img_pano1 + img_pano2) / 2\n",
    "imshow( img_pano )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像の足し算ではいまいち．各画素のmaxをとってみよう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "img_pano = np.maximum(img_pano1 , img_pano2)\n",
    "imshow( img_pano )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
