{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import cv2 \n",
    "from PIL import Image\n",
    "import glob\n",
    "from skimage import feature\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import pywt\n",
    "import re\n",
    "import copy\n",
    "import random\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_contour(image):\n",
    "    obj_dict = {}\n",
    "    retval, bw = cv2.threshold(image, 50, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    contours, hierarchy = cv2.findContours(bw, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    detect_count = 0\n",
    "\n",
    "    for i in range(0, len(contours)):\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        \n",
    "        if area < 1e2 or 1e5 < area:\n",
    "            continue\n",
    "            \n",
    "        if len(contours[i]) > 0:\n",
    "            rect = contours[i]\n",
    "            x, y, w, h = cv2.boundingRect(rect)\n",
    "            \n",
    "            angle_data = cv2.minAreaRect(contours[i])\n",
    "            angle = angle_data[2]\n",
    "            point = [y, y+h, x, x+w, angle]\n",
    "            w_h = w + h\n",
    "            obj_dict[w_h] = point \n",
    "    return obj_dict[max(obj_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def burst_wave(img, wavelet_list, level, IMAGE_WIDTH=640, IMAGE_HEIGHT=480, M_WAVELET=\"db1\", mode=\"sym\"):\n",
    "    img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    data = img.astype(np.float64)\n",
    "    coeffs = pywt.wavedec2(data, M_WAVELET, level=level, mode=mode)\n",
    "\n",
    "    wavelet_data = np.array([])\n",
    "    for i, data in enumerate(coeffs):\n",
    "        data = np.ravel(data)\n",
    "        wavelet_data = np.append(wavelet_data, data)\n",
    "    wavelet_list.append(wavelet_data)\n",
    "    \n",
    "    return wavelet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_path = glob.glob('image_folder/*/*color*')\n",
    "depth_path = []\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(color_path)\n",
    "for path in color_path:\n",
    "    new_path = path.replace('color', 'depth')\n",
    "    depth_path.append(new_path)\n",
    "    \n",
    "train_color = color_path[:70]\n",
    "train_depth = depth_path[:70]\n",
    "\n",
    "test_color = color_path[70:]\n",
    "test_depth = depth_path[70:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wave_feature(color_paths, depth_paths, mode):\n",
    "    wavelet_list = []\n",
    "    name_list = []\n",
    "    LEVEL = 5\n",
    "    for color_path, depth_path in zip(color_paths, depth_paths):\n",
    "        depth_image = cv2.imread(depth_path, 0)\n",
    "        color_image = cv2.imread(color_path, 0)\n",
    "\n",
    "        # y_trainの作成\n",
    "        slash_index = color_path[13:].find('/')\n",
    "        name_list.append(color_path[13:13+slash_index])\n",
    "\n",
    "        image_list = []\n",
    "        depth_copy = copy.deepcopy(depth_image)\n",
    "        color_copy = copy.deepcopy(color_image)\n",
    "\n",
    "        for col in depth_image:\n",
    "            for one in col:\n",
    "                if one > 1000:\n",
    "                    image_list.append(0)\n",
    "                else:\n",
    "                    image_list.append(one)\n",
    "\n",
    "        for y, col in enumerate(depth_image):\n",
    "            for x, pixel in enumerate(col):\n",
    "                if pixel > 0 and pixel < 390: \n",
    "                    depth_image[y][x] = 255\n",
    "                else:\n",
    "                    depth_image[y][x] = 0\n",
    "        image = np.array(depth_image, dtype=np.uint8)\n",
    "\n",
    "        y1, y2, x1, x2, angle = detect_contour(image)\n",
    "        img = color_image[y1:y2, x1:x2]\n",
    "        depth_cut = depth_copy[y1:y2, x1:x2]\n",
    "\n",
    "        wavelet_list = burst_wave(img, wavelet_list, level=5, IMAGE_WIDTH=640, IMAGE_HEIGHT=480, M_WAVELET=\"db1\", mode=\"sym\")\n",
    "\n",
    "    X_train = np.array(wavelet_list)\n",
    "    \n",
    "    if mode == 'train':\n",
    "        y_dict = {}\n",
    "        le = LabelEncoder()\n",
    "        y_train = le.fit_transform(name_list)\n",
    "        decoded = le.inverse_transform(y_train)\n",
    "\n",
    "        for name, name_id in zip(decoded, y_train):\n",
    "            y_dict[name_id] = name\n",
    "        return X_train, y_train, y_dict\n",
    "    else:\n",
    "        return X_train\n",
    "    \n",
    "    return train_wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, y_dict = make_wave_feature(train_color, train_depth, 'train')\n",
    "X_test = make_wave_feature(test_color, test_depth, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 307200)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris\n",
      "apple\n",
      "curry\n",
      "curry\n",
      "kurumiB\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test[0])\n",
    "for index in y_pred:\n",
    "    print(y_dict[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image_folder/iris/iris_color_1.jpg',\n",
       " 'image_folder/apple/apple_color_0_221.jpg',\n",
       " 'image_folder/curry/curry_color_0_868.jpg',\n",
       " 'image_folder/kurumiA/kurumiA_color_0.jpg',\n",
       " 'image_folder/kurumiA/kurumiA_color_0_346.jpg']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
